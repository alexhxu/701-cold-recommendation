{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTqSh0054Gl5"
      },
      "source": [
        "Modules import and set up. (Running with Google Colab Python3 on T4 GPU.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GT_PGUFl4NMW"
      },
      "outputs": [],
      "source": [
        "# import os, time, json, copy, pickle, random, requests, re\n",
        "import numpy as np\n",
        "# from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4VMQZHXTreH"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read the movie and ratings files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "movies_path = \"movies.dat\"\n",
        "ratings_path = \"ratings.dat\"\n",
        "\n",
        "def create_films_dict(file_path):\n",
        "    master_dict = {}\n",
        "    with open(file_path, \"r\", encoding=\"latin-1\") as file:\n",
        "        for line in file:\n",
        "            full_line = line.strip()\n",
        "            id = int(full_line.split(\"::\")[0])\n",
        "            master_dict[id] = full_line\n",
        "    return master_dict\n",
        "\n",
        "def create_ratings_matrix(file_path):\n",
        "    full_array = []\n",
        "    with open(file_path, \"r\", encoding = \"latin-1\") as file:\n",
        "        for line in file:\n",
        "            full_line = line.strip()\n",
        "            full_array.append(full_line)\n",
        "        as_np_array = np.array(full_array)\n",
        "    return as_np_array\n",
        "filmsdict = create_films_dict(movies_path)\n",
        "ratingsmat = create_ratings_matrix(ratings_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(filmsdict[1])\n",
        "print(ratingsmat[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH8v4PtF9BAS"
      },
      "source": [
        "Reference: https://huggingface.co/google-bert/bert-base-uncased"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7liIiE6Y7lE8"
      },
      "outputs": [],
      "source": [
        "# Load BERT model\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\",\n",
        "                                  output_hidden_states=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqr2w2lF3YbU"
      },
      "source": [
        "Generate vector with BERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IzNNfGb3VVq"
      },
      "outputs": [],
      "source": [
        "def get_vector_batch(texts, batch_size=16):\n",
        "  bert_model.eval()\n",
        "  all= []\n",
        "  for i in tqdm(range(0, len(texts), batch_size)):\n",
        "    batch = texts[i:i+batch_size]\n",
        "    encoded_input = bert_tokenizer(batch, return_tensors='pt', padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "          output = bert_model(**encoded_input)\n",
        "          hidden_states = output.hidden_states\n",
        "          # print(len(hidden_states))\n",
        "    last4 = torch.stack(hidden_states[-4:]).sum(0)\n",
        "    # print(last4.shape)\n",
        "    embedding = last4.mean(dim=1)\n",
        "    all.append(embedding)\n",
        "  # print(embedding.shape)\n",
        "  return torch.cat(all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVPO0Qd4Q8CX",
        "outputId": "2a51762d-881b-46cf-b14b-5d59e5cd994a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 768])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#testing\n",
        "vec = get_vector_batch([\"hello world bro i dont know what else to Say what's wrong\", \"wha tis going on\"])\n",
        "# print(vec)\n",
        "print(vec.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0j3HJNU7xEi"
      },
      "source": [
        "Implement Deep AutoEncoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "va-ghqhC72fX"
      },
      "outputs": [],
      "source": [
        "class DeepAutoEncoder(nn.Module):\n",
        "  # could be modified to just take in a dims list\n",
        "  def __init__(self, input_dim=768, hidden_dim=64):\n",
        "    super().__init__()\n",
        "    self.encoder = nn.Sequential(\n",
        "        nn.Linear(input_dim, 512),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(512, 256),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(256, 128),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(128, hidden_dim)\n",
        "      )\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.Linear(bottleneck_dim, 128),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(128, 256),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(256, 512),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Linear(512, input_dim),\n",
        "      )\n",
        "  def forward(self, x):\n",
        "    reduced = self.encoder(x)\n",
        "    reconstructed = self.decoder(reduced)\n",
        "    return reduced, reconstructed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D28K4BwqJ08U"
      },
      "source": [
        "Dataloader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Onw0XBfJ0Od"
      },
      "outputs": [],
      "source": [
        "def get_dataloader(trainset, valset = None, batch_size = 64, num_workers = 2):\n",
        "    train_loader = DataLoader(trainset, shuffle=True, num_workers=num_workers, batch_size=batch_size)\n",
        "    if valset:\n",
        "      val_loader = DataLoader(valset, shuffle=False, num_workers=num_workers, batch_size=batch_size)\n",
        "      return (train_loader, val_loader)\n",
        "    return (train_loader, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlDz-o5cLIYR"
      },
      "outputs": [],
      "source": [
        "class ItemProfileDataset(Dataset):\n",
        "    def __init__(self,input):\n",
        "        \"\"\"\n",
        "        input: (num_items, 768) tensor\n",
        "        \"\"\"\n",
        "        self.vecs = input\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.vecs.size(0)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        v = self.vecs[idx]\n",
        "        return v, v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWLCVorq724q"
      },
      "source": [
        "Training DAE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nw18tVSqKZGB"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()\n",
        "trainset = ItemProfileDataset(vec) #validation set needs to be set later\n",
        "valset = None\n",
        "# train_loader, val_loader = get_dataloader(trainset, valset)\n",
        "# optimizer =\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7pI78Qj764b"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, train_loader, optimizer):\n",
        "  start = time.time()\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  for x, y in tqdm(train_loader):\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      # x = x.view(x.size(0), -1)\n",
        "      # print(x.shape, y.shape)\n",
        "      _, out = model.forward(x)\n",
        "      loss = criterion(out, y)\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      # out = out.view(out.size(0), -1)\n",
        "\n",
        "      # print(out.shape)\n",
        "      # print(y.shape)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "  avg_loss = total_loss / len(train_loader)\n",
        "  end = time.time()\n",
        "  return (avg_loss, end - start)\n",
        "\n",
        "def validate_model(model, val_loader):\n",
        "    start = time.time()\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "      for x, y in tqdm(val_loader):\n",
        "          x = x.to(device)\n",
        "          y = y.to(device)\n",
        "          # x = x.view(x.size(0), -1)\n",
        "          # print(x.shape, y.shape)\n",
        "          _, out = model.forward(x)\n",
        "          loss = criterion(out, y)\n",
        "          total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(val_loader)\n",
        "    end = time.time()\n",
        "    return (avg_loss, end - start)\n",
        "\n",
        "def train_model(model, n_epochs, train_loader, val_loader, optimizer, scheduler = None, verbose = False):\n",
        "    best_loss = float('inf')\n",
        "    best_state = None\n",
        "    # best_model = None\n",
        "    best_epoch_num = 0\n",
        "    train_losses = []\n",
        "    total_time = 0\n",
        "    for i in range(n_epochs):\n",
        "        train_loss, train_time = train_one_epoch(model, train_loader, optimizer)\n",
        "        val_loss, val_time = validate_model(model, val_loader)\n",
        "        train_losses.append(train_loss)\n",
        "        total_time += train_time + val_time\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_state = copy.deepcopy(model.state_dict())\n",
        "            best_epoch_num = i + 1\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "    model.load_state_dict(best_state)\n",
        "    return (model, best_epoch_num, train_losses, total_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5KwNdagXlCF"
      },
      "outputs": [],
      "source": [
        "def train_and_save_model(model, optimizer, batch_size=64, n_epochs=10, scheduler=None, filepath=None, verbose=False):\n",
        "    model.to(device)\n",
        "    train_loader, val_loader = get_dataloader(full_trainset, full_valset, batch_size)\n",
        "    if filepath is None:\n",
        "        filepath = f\"models/trained_{model.__class__.__name__}.pt\"\n",
        "    best_model, best_loss_epoch_num, train_losses, total_time = train_model(model, n_epochs, train_loader, val_loader, optimizer, scheduler, verbose)\n",
        "    torch.save(best_model.state_dict(), filepath)\n",
        "    return (best_model, best_loss_epoch_num, total_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48LnQFY4WE4s"
      },
      "outputs": [],
      "source": [
        "model = DeepAutoEncoder()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay = 5e-4)\n",
        "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lambda epoch: 0.95 * epoch)\n",
        "best_model, best_loss_epoch_num, total_time = train_and_save_model(model, optimizer, scheduler=scheduler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTl5G3v0YLCB"
      },
      "source": [
        "Using DAE to reduce dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDyCeLqqYWNL"
      },
      "outputs": [],
      "source": [
        "def get_reduced(model, input):\n",
        "  data = torch.FloatTensor(input).to(device)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    reduced, _ = model.forward(data)\n",
        "  return reduced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZWQcNUzUMJt"
      },
      "outputs": [],
      "source": [
        "# actually run it on all the data passed in"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttYJHtT08B6b"
      },
      "source": [
        "Implement factorization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KzvgdcEzjgK"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(X):\n",
        "  X = X.numpy()\n",
        "  numer = X @ X.T\n",
        "\n",
        "  sq = np.square(X)\n",
        "  sq_sum = sq.sum(axis=1)\n",
        "  sqrt_sum = np.sqrt(sq_sum)\n",
        "  denom = np.outer(sqrt_sum, sqrt_sum)\n",
        "\n",
        "  result = np.divide(numer, denom)\n",
        "  # print(result)\n",
        "  result = torch.from_numpy(result)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMu1K0O58JEG"
      },
      "outputs": [],
      "source": [
        "class MF(nn.Module):\n",
        "  def __init__(self, num_users, num_items, num_factors=20, theta: torch.Tensor = None,  # [num_items, d]\n",
        "                 k = 3,\n",
        "                 beta= 0.01):\n",
        "    \"\"\"\n",
        "    theta: the iteem profiles acquired from BERT+DAE\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.num_users = num_users\n",
        "    self.num_items = num_items\n",
        "    self.f = num_factors\n",
        "    self.beta = beta\n",
        "    self.P = nn.Embedding(num_users, num_factors)\n",
        "    self.Q = nn.Embedding(num_items, num_factors)\n",
        "\n",
        "    #initialize randomly\n",
        "    nn.init.normal_(self.P.weight, std=0.01)\n",
        "    nn.init.normal_(self.Q.weight, std=0.01)\n",
        "\n",
        "    if theta is not None:\n",
        "      self.get_k_neighbors(theta, k)\n",
        "    else:\n",
        "      self.i_plus = None\n",
        "      self.i_sims = None\n",
        "\n",
        "    self.register_buffer(\"gamma\", torch.ones(num_items))\n",
        "\n",
        "  # get the k most similar items to each item\n",
        "  def get_k_neighbors(self, theta, k):\n",
        "    sim = cosine_similarity(theta)\n",
        "    sim.fill_diagonal_(0)\n",
        "    val, idx = torch.topk(sim, k=k, dim=1)\n",
        "    self.register_buffer(\"i_plus\", idx)\n",
        "    self.register_buffer(\"i_sims\", val)\n",
        "\n",
        "  def set_gamma(self, item_count, z=5.0):\n",
        "    count = item_count.float().clamp_min(1.0)\n",
        "    self.gamma = z / count\n",
        "\n",
        "  def forward(self, user_id, item_id):\n",
        "    p = self.P(user_id)\n",
        "    q = self.Q(item_id)\n",
        "    return (p * q).sum(1)\n",
        "\n",
        "  # objective function\n",
        "  def loss(self, user_id, item_id, rating):\n",
        "    pred = self.forward(user_id, item_id)\n",
        "    error = 0.5 * (rating - pred).square().sum()\n",
        "\n",
        "    p = self.P(user_id)\n",
        "    q = self.Q(item_id)\n",
        "    reg = self.beta * (p.square().sum() + q.square().sum())\n",
        "\n",
        "    if (self.i_plus is not None) and (self.i_sims is not None):\n",
        "      unique = torch.unique(item_id)\n",
        "      q_self = self.Q(unique)\n",
        "      q_neighbor = self.Q(self.i_plus[unique])\n",
        "      diff = (q_self.unsqueeze(1) - q_neighbor).square().sum(dim=2)\n",
        "      sim = self.i_sims[unique]\n",
        "      gamma = self.gamma[unique].unsqueeze(1)\n",
        "      reg += (diff * sim * gamma).sum()\n",
        "    return error + reg\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXBEy-aO4Yk1"
      },
      "outputs": [],
      "source": [
        "def train_MF_epoch(model, train_loader, optimizer):\n",
        "  model.train()\n",
        "  total_loss = 0.0\n",
        "  for u, i, r in tqdm(train_loader):\n",
        "      u = u.to(device)\n",
        "      i = i.to(device)\n",
        "      r = r.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss = model.loss(u, i, r)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      total_loss += loss.item()\n",
        "\n",
        "  return total_loss / len(loader)\n",
        "\n",
        "def train_MF(model, n_epochs, train_loader, optimizer, verbose=False):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "      avg_loss = train_epoch(model, train_loader, optimizer, device)\n",
        "      print(f\"Epoch {epoch:02d} | loss = {avg_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3AwxjkP8JgN"
      },
      "source": [
        "Construct ALDRS class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eqi_G1Zf8L0z"
      },
      "outputs": [],
      "source": [
        "class RatingsDataset(Dataset):\n",
        "  def __init__(self, user_ids, item_ids, ratings):\n",
        "    self.user_ids = torch.as_tensor(user_ids, dtype=torch.long)\n",
        "    self.item_ids = torch.as_tensor(item_ids, dtype=torch.long)\n",
        "    self.ratings = torch.as_tensor(ratings,  dtype=torch.float32)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.ratings)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return (\n",
        "      self.user_ids[idx],\n",
        "      self.item_ids[idx],\n",
        "      self.ratings[idx],\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQ2ViXB3Bk4t"
      },
      "outputs": [],
      "source": [
        "def run_adlrs_pipeline(\n",
        "  ratings,\n",
        "  users,\n",
        "  items, #this is the supporting item profiles\n",
        "  DAE_model,\n",
        "  num_factors=20,\n",
        "  k_neighbors=3,\n",
        "  z_gamma=5.0,\n",
        "  batch_size=64,\n",
        "  num_epochs=20,\n",
        "  lr=1e-2,\n",
        "):\n",
        "\n",
        "    # ---------- 0. Map raw ids to 0..N-1 (if needed) ----------\n",
        "    # subject to change of the actual data\n",
        "    # user2idx = {u: i for i, u in enumerate(sorted(ratings_df[\"user_id\"].unique()))}\n",
        "    # item2idx = {i: j for j, i in enumerate(sorted(ratings_df[\"item_id\"].unique()))}\n",
        "\n",
        "    # ratings_df = ratings_df.copy()\n",
        "    # ratings_df[\"u_idx\"] = ratings_df[\"user_id\"].map(user2idx)\n",
        "    # ratings_df[\"i_idx\"] = ratings_df[\"item_id\"].map(item2idx)\n",
        "\n",
        "    # num_users = len(user2idx)\n",
        "    # num_items = len(item2idx)\n",
        "\n",
        "    # # Make sure items_df is aligned with item indices\n",
        "    # items_df = items_df.copy()\n",
        "    # items_df[\"i_idx\"] = items_df[\"item_id\"].map(item2idx)\n",
        "    # items_df = items_df.dropna(subset=[\"i_idx\"])\n",
        "    # items_df[\"i_idx\"] = items_df[\"i_idx\"].astype(int)\n",
        "\n",
        "    ##### Item Embedding\n",
        "\n",
        "    item_indices = items.index.tolist()\n",
        "    texts = items.copy()\n",
        "\n",
        "    bert_vecs = get_vector_batch(texts, batch_size).to(device)\n",
        "    reduced = get_reduced(DAE_model, bert_vecs).to(device)\n",
        "\n",
        "    ##### Build ADLRS MF model & compute γ and neighbors\n",
        "    model = MF(\n",
        "      num_users=num_users,\n",
        "      num_items=num_items,\n",
        "      num_factors=num_factors,\n",
        "      theta=reduced,\n",
        "      k=k_neighbors,\n",
        "      beta=0.01,\n",
        "    ).to(device)\n",
        "\n",
        "    # per-item rating counts for γ = z / count(i)\n",
        "    item_counts = torch.bincount(\n",
        "        torch.as_tensor(ratings_df[\"i_idx\"].values, dtype=torch.long),\n",
        "        minlength=num_items,\n",
        "    )\n",
        "    model.set_gamma(item_counts, z=z_gamma)\n",
        "\n",
        "    # ---------- 3. Prepare rating DataLoader ----------\n",
        "    train_dataset = RatingsDataset(\n",
        "        ratings_df[\"u_idx\"].values,\n",
        "        ratings_df[\"i_idx\"].values,\n",
        "        ratings_df[\"rating\"].values,\n",
        "    )\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # ---------- 4. Train MF (Algorithm 1 lines 10–18) ----------\n",
        "    # train_MF should implement the SGD loop that calls model.loss(...)\n",
        "    trained_model = train_MF(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        num_epochs=num_epochs,\n",
        "        lr=lr,\n",
        "        device=device,\n",
        "    )\n",
        "\n",
        "    # ---------- 5. Return everything we might want later ----------\n",
        "    return {\n",
        "        \"model\": trained_model,\n",
        "        \"theta\": reduced,               # BERT+DAE item profiles\n",
        "        \"user2idx\": user2idx,\n",
        "        \"item2idx\": item2idx,\n",
        "    }\n",
        "\n",
        "def get_rating_pred(model, user_id, item_id):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    pred = model.forward(user_id, item_id)\n",
        "  return pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yMcxEio8MWf"
      },
      "source": [
        "Implement evaluation metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQesBZlO8QJ5"
      },
      "outputs": [],
      "source": [
        "def MAE(y_true, y_pred):\n",
        "  return np.mean(np.abs(y_pred - y_true))\n",
        "\n",
        "def RMSE(y_true, y_pred):\n",
        "  return np.sqrt(np.mean((y_pred - y_true).square()))\n",
        "\n",
        "def HR(scores, user_items, N):\n",
        "  \"\"\"\n",
        "  Compute Hit Ratio @ N for the whole dataset.\n",
        "\n",
        "  Args:\n",
        "      scores (dict): user_id -> {item_id: predicted_score}\n",
        "      user_items (dict): user_id -> set of ground-truth relevant items\n",
        "      N (int): cutoff N in top-N\n",
        "\n",
        "  Returns:\n",
        "      float: Hit Ratio @ N\n",
        "  \"\"\"\n",
        "  hits = 0\n",
        "  users = 0\n",
        "\n",
        "  for user, relevant_items in user_items.items():\n",
        "\n",
        "      # Skip users with no ground truth items\n",
        "      if len(relevant_items) == 0:\n",
        "          continue\n",
        "\n",
        "      users += 1\n",
        "\n",
        "      # sort scores for this user, descending\n",
        "      ranked_items = sorted(scores[user].items(),\n",
        "                            key=lambda x: x[1],\n",
        "                            reverse=True)\n",
        "\n",
        "      # take top-N item IDs\n",
        "      topN_items = [item for item, _ in ranked_items[:N]]\n",
        "\n",
        "      # check if *any* relevant item appears in top-N\n",
        "      if any(item in topN_items for item in relevant_items):\n",
        "          hits += 1\n",
        "\n",
        "  # avoid division by zero\n",
        "  if users == 0:\n",
        "      return 0.0\n",
        "\n",
        "  return hits / users\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
